## 1 数据处理

#### 第一版代码：标点分割，空格切割，使用低频词和填充词
#### 第二版代码：sacremoses处理，使用低频词和填充词

## 2 TextCNN模型参数

#### 第一版代码：nums_channels=[100, 100, 100]，kernel_size=[3, 4, 5]
#### 第二版代码：nums_channels=[50, 50, 50]，kernel_size=[3, 4, 5]，nums_channels=100的话前50个epoch准确率在50+%，nums_channels=70准确率在60+%，nums_channels=30准确率在50+%，nums_channels=50在前10个epoch准确率就可以达到80%

## 3 优化器参数
#### 第一版代码：lr设置成1e-1的话大概前三轮就会过拟合，所以从1e-2开始（此时没有使用weight_decay）。当lr降低至1e-5时，开始设置weight_decay参数，尝试1e-7，1e-4，1e-1。后续再调准确率也基本不变了。
#### 第二版代码：lr设置成1e-2，batch_size设置成512，运行100个epoch准确率可以升到88%左右。然后设置1e-3，运行50个epoch升到89%。尝试继续降低lr至1e-4，但是准确率没有明显改变，所以在lr=1e-3的基础上使用weight_decay，weight_decay=1e-7也没有明显变化，weight_decay=1e-3的时候大概每经过10个epoch能增加0.1%的准确率。在准确率升到90%的时候每经过10个epoch能增加0.04%的准确率，快接近90.5%的时候怎么调准确率都升不上去了。

##### 注意：在进行分词处理时，‘[UNK]’和‘[PAD]’符号要设置成列表的形式，也就是[['[UNK]'],['[PAD]']]，不然在word2vec里会自动切割成‘\‘’，’[‘，‘U’，‘N’，‘K’...
